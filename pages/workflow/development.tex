\subsection{Desarrollo dentro de proyectos}
Una vez que un nuevo miembro ha superado el periodo de integración,
ya está listo para comenzar a trabajar en proyectos. En esta subsección
se describen los procesos que se siguen para el desarrollo de un
proyecto desde cero, así como las directrices generales para
garantizar la calidad y la reproducibilidad del mismo. Para garantizar 
que esta metodología es funcional y de verdad aporta una mejora en la
se han realizado dos proyectos para cada una de las áreas de
trabajo de las series temporales, \textit{forecasting} y \textit{clasificación}
y \textit{detección de anomalías}. Por último, se ha hecho una plantilla
adicional de automl para utilizar una serie de componentes dentro de 
un proyecto de \textit{forecasting}.

\subsubsection{Flujo de trabajo}
El flujo de trabajo que se sigue para el desarrollo de un proyecto
es el siguiente:
\begin{enumerate}
    \item \textbf{Creación del proyecto:} para comenzar un proyecto, el
    investigador deberá revisar dentro de la documentación del equipo
    si existe alguna plantilla que se ajuste a sus necesidades y, en caso
    de que esta se adapte a lo que busca, podrá crear un nuevo proyecto
    a partir de esta plantilla. En caso de que no exista una plantilla
    que específica para ese caso de uso, se da la alternativa de utilizar
    una plantilla de otro caso de uso ya que puede ser que ciertas configuraciones
    específicas de librerías le sean de utilidad para no partir de cero.
    Si no se cumplen ninguno de los dos casos anteriores, se presenta una
    plantilla genérica que se puede utilizar para cualquier proyecto. En casos
    excepcionales, se puede crear un proyecto desde cero pero debe seguir los
    estándares de calidad definidos en su respectiva sección y ser perfectamente
    reproducible.
    \item \textbf{Control de versiones:} una vez que el proyecto ha sido creado,
    el investigador deberá subir el proyecto a un repositorio de control de versiones,
    en este caso se utiliza Git-Lab. El siguiente paso es utilizar las funciones de 
    ClearML para versionar los datasets que se requieran para el desarrollo del proyecto.
    No existe una imposición sobre como gestionar las ramas de git, cada investigador
    puede decidir como adaptarlo dependiendo del proyecto, equipo o el número de integrantes.
    Las directrices generales son la utilización de la rama \textit{main} para versiones
    estables del modelo, es decir un entrenamiento e inferencia funcional, y la rama 
    \textit{dev} para versiones en desarrollo.
    \item \textbf{Desarrollo y experimentación:} para garantizar el buen desarrollo del proyecto, se
    recomienda mantener el histórico de resultados de los experimentos que se realicen
    en el proyecto. Por defecto, el proyecto ya viene configurado para que se guarden
    los resultados de los experimentos en ClearML, a si que se recomienda eliminar 
    aquellos que hayan fallado o que sean irrelevantes con el objetivo de poder
    lanzar nuevamente esos experimentos en un futuro. Se recomienda seguir
    las indicaciones de los \textit{linters} y \textit{formatters} que se han configurado
    para garantizar la consistencia y claridad del código, aunque se puede desactivar
    para casos específicos como es el caso de errores de tipado. El uso del catálogo
    de componentes es opcional, pero es de gran utilidad para agilizar ciertas tareas
    repetitivas.
    \item \textbf{Aportación al sistema de conocimiento:} una vez que el proyecto
    ha sido finalizado, se recomienda aportar al sistema de conocimiento del equipo
    para que otros miembros puedan beneficiarse del nuevo conocimiento. Si
    no existía una plantilla específica para ese caso de uso, lo ideal es crear
    una nueva plantilla para esa especificación ya que es mucho más sencillo
    y requiere menos esfuerzo que crear un componente. En caso de que ya hayamos
    usado una plantilla, también se podrá crear otra si la solución que
    se ha encontrado es significativamente diferente a la original. Por último,
    si no se cumplen ninguno de los dos casos anteriores, y hay funcionalidades
    que se pueden reutilizar en otros proyectos sería recomendable crear un
    componente.
\end{enumerate}

% Hablar aquí de las tres aportaciones que se han hecho Forecasting, 
\subsubsection{Puesta en practica de la metodología}
En este apartado se describe la experiencia de desarrollo de
los proyectos de \textit{forecasting} y \textit{clasificación} y \textit{detección de anomalías}.
Esta sección no pretende centrarse en los resultados obtenidos por parte de los modelos, sino
más bien llevar a cabo una reflexión sobre la aplicabilidad del marco de trabajo
dentro de diferentes tipos de proyectos. Los datasets utilizados se eligieron siguiendo el criterio de 
pertenecer a la sección de "Industria y movilidad", correspondiente al área de trabajo donde 
se quiere aplicar dicho marco, y de estar relacionados con el campo 
de las series temporales. Estos proyectos se han basado en datasets extraídos de la plataforma Kaggle, 
ya que es una plataforma que ofrece una gran variedad de datasets que no requieren un registro previo para su descarga.\medskip

Para considerar un proyecto como terminado, se requiere que el modelo sea capaz de realizar inferencias 
sobre nuevos datos con cierta precisión. Además, se espera que pueda generar gráficos que muestren los 
resultados de manera clara y comprensible. Otro de los requisitos es que las métricas de entrenamiento
y evaluación sean almacenadas en ClearML, asi como los modelos entrenados. Por último, se espera un ligero
análisis de los parámetros con su gráfico resultante. Una vez que estas condiciones se cumplan, 
se considera que el proyecto está completo y listo para su evaluación. La evaluación de los proyectos
se compone de dos factores, el tiempo dedicado a la realización del proyecto y el porcentaje de código
que ha sido reutilizado de otros proyectos.

\subsubsection{Proyectos de forecasting}
Los proyectos de forecasting se basan en la predicción de una variable a lo largo del tiempo.
Implica el análisis de datos históricos para identificar patrones y tendencias que ayuden 
a predecir el comportamiento futuro. Este tipo de proyectos pueden abordar preguntas como la 
demanda futura de productos, la evolución de la demanda en un mercado, entre otros aspectos. 
El objetivo principal es proporcionar información útil para la toma de decisiones, permitiendo a 
las organizaciones anticiparse a cambios y optimizar recursos.\medskip

A continuación, se detallan las características de los siguientes proyectos:
\begin{itemize}
    \item \textbf{Proyecto 1:} en este proyecto nuestro objetivo es predecir 
    la temperatura para un día especifico dentro de una zona determinada. 
     El nombre del dataset es \textit{Daily Climate Temperature Data}
    \cite{Daily_Climate}. Este dataset contiene información sobre la temperatura
    de la ciudad de Delhi, India desde 2013 hasta 2017. El dataset cuenta con
    variables como temperatura media, la humedad, la velocidad del viento, entre otras.
    La calidad de los datos es buena, no hay valores nulos y las variables están
    en un formato adecuado para su uso.
    \item \textbf{Proyecto 2:} en el segundo proyecto, el objetivo es predecir
    el consumo de energía eléctrica en una zona determinada. El nombre del dataset
    es \textit{Hourly Energy Consumption} \cite{Hourly_Energy}. Este dataset contiene
    información sobre el consumo de energía eléctrica en la ciudad de Nueva York desde
    2002 hasta 2018. El dataset cuenta exclusivamente con la fecha y la cantidad de energía
    consumida, por lo que es ligeramente más sencillo que el anterior.
\end{itemize}

Para el primer proyecto, no se disponía de ninguna plantilla específica, por lo que se 
decidió comenzar el desarrollo desde cero. Con la intención de reutilizar el máximo
número de código en futuros proyectos, se ha planteado el desarrollo desde un punto
de vista modular, donde cada funcionalidad esta separada en un archivo diferente.
Todas estas funcionalidades se importan y utilizan en el archivo de entrenamiento
principal llamado \textit{train.py}. Entre las funcionalidades que se han desarrollado
podemos encontrar diferentes tipos: procesamiento, visualización, métricas, etc. A continuación,
se detallan mas concretamente cada una de ellas:

\begin{itemize}
    \item \textbf{add\_time\_features (Procesamiento):} esta funcionalidad se encarga de añadir
    características temporales a un DataFrame de Pandas. A partir de la fecha se calcula
    el día de la semana, el mes, el año, la estación, entre otras.
    \item \textbf{mean\_abs\_percentage\_error (Métrica):} calcula el error porcentual medio
    absoluto entre dos valores. Utilizada para evaluar el rendimiento del modelo y al no
    ser una métrica nativa de Sklearn, se ha tenido que implementar.
    \item \textbf{compare\_time\_series (Visualización):} recibe un DataFrame con n columnas,
    una para cada serie temporal, y crea una gráfica comparativa de todas ellas. También
    se puede especificar un rango de fechas para visualizar solo un periodo concreto.
    \item \textbf{show\_feature\_importance (Visualización):} Recibe un array de importancia
    de características y un array con los nombres de las características. Crea un gráfico
    de barras con la importancia de cada característica.
\end{itemize}

Con estos funcionalidades y utilizando algunas propias de sklearn, como el split
de los datos y XGBoost como modelo, se ha conseguido un modelo que es capaz de predecir
la temperatura con un error medio absoluto porcentual del 9.5\%. Este proyecto ha tenido
una duración aproximada de 3 horas y media. Una vez finalizado, se ha realizado una
plantilla basada en este proyecto para futuros proyectos de forecasting donde se necesite
xgboost como modelo. Esta plantilla asi como los componentes relacionados se detalla más
adelante en la sección de \textit{contribución al sistema de conocimiento}.\medskip

Para el segundo proyecto, se ha utilizado la plantilla de forecasting creada
a partir del primer proyecto. Las modificaciones realizadas han sido mínimas,
ya que el proyecto es muy similar al anterior. Se ha cambiado la lectura de
datos para adaptarla al nuevo dataset y se han implementado algunas funcionalidades
adicionales para la extracción de características ya que el dataset no cuenta con
muchos datos relevantes. Antes de comenzar con la implementación de características,
utilizando la funcionalidad \textit{add\_time\_features}, el modelo a obtenido un error
medio absoluto porcentual del 15.5\%. Tras la implementación de nuevas características
que se pueden ver a continuación, el error ha disminuido hasta el 11.5\%:

\begin{itemize}
    \item \textbf{add\_lags (Procesamiento):} añade valores pasados de una serie temporal
    como características adicionales llamados lags. Se puede especificar el número de lags
    y el periodo de tiempo que se quiere utilizar.
    \item \textbf{add\_holidays (Procesamiento):} añade una columna al DataFrame que indica
    si el día es festivo o no. Esta función recibe un calendario con los días festivos
    y crear una columna con valores booleanos. Para este proyecto se ha utilizado el calendario
    de festivos de Nueva York.
\end{itemize}

Este proyecto ha tenido una duración aproximada de 1 hora y 40 minutos. Una vez finalizado,
se ha actualizado la plantilla de forecasting con nuevas funcionalidades y extraído cierta
lógica de la plantilla a componentes para facilitar la reutilización de código. Hemos visto
una mejora en cuanto a la velocidad de desarrollo ya que el tiempo desde la creación del proyecto
hasta la finalización ha sido reducido a menos de la mitad.

\subsubsection{Proyectos de clasificación}
Un proyecto de clasificación de series temporales implica el desarrollo de modelos para 
categorizar o etiquetar datos temporales en diferentes categorías. La clasificación de 
series temporales implica generalmente la extracción de características relevantes 
de las series temporales y el objetivo es identificar y asignar correctamente una 
etiqueta a cada serie temporal.\medskip

Para los proyecto de clasificación contamos con la siguiente temáticas.

\begin{itemize}
    \item \textbf{Proyecto 1:} clasificación de la estación en del año en base al consumo de energía eléctrica.
    Se ha utilizado el dataset \textit{Daily Energy Consumption} \cite{Hourly_Energy} al igual
    que en el proyecto de forecasting. De por si este dataset no cuenta con la variable estación,
    por lo que parte de la tarea es la de identificar la estación en base a la fecha.
    \item \textbf{Proyecto 2:} en el segundo proyecto se ha utilizado el mismo dataset pero se ha
    cambiado las herramientas utilizadas. En este caso, se va a utilizar una librería 
    llamada Sktime que es una librería especializada en series temporales.
\end{itemize}

Siguiendo la misma metodología que en los proyectos de forecasting, se ha comenzado
el desarrollo del primer proyecto pero esta vez partiendo de la plantilla de forecasting,
ya que viene configurada con todas las utilidades necesarias y solo se necesita cambiar
aspectos puntuales para adaptarla a un problema de clasificación. Como ya hemos mencionado
en la descripción del proyecto, nuestro dataset no cuenta con la variable estación, por lo
que tendremos que añadirla, agruparlas en ventanas temporales y hacer las respectivas modificaciones
para que pueda ser interpretado por el modelo.\medskip

A continuación, se detallan la lista de modificaciones y funcionalidades que se han llevado a cabo:

\begin{itemize}
    \item \textbf{add\_time\_features (Procesamiento):} añade una nueva funcionalidad que
    consiste en una aportar de una columna adicional al DataFrame que indica
    la estación en la que se encuentra una fecha en concreto. Esta se representa con un número entero
    que va del 0 al 3, siendo 0 invierno, 1 primavera, 2 verano y 3 otoño.
    \item \textbf{get\_window (Procesamiento):} realiza una agrupación de los datos en ventanas
    temporales. Se puede especificar el tamaño de la ventana y el periodo de tiempo que se quiere
    utilizar. En este caso, se ha agrupado los datos en ventanas de 10 días.
    \item \textbf{cross\_validation (Métrica):} realiza una validación cruzada de los datos
    para evaluar el rendimiento del modelo. Se puede especificar el número de splits y el tamaño
    de los splits. 
    \item \textbf{display\_roc\_curve (Visualización):} recibe un array con las etiquetas reales
    y otro con las predicciones del modelo. Crea una curva ROC que muestra la relación entre
    la tasa de verdaderos positivos y la tasa de falsos positivos. Este gráfico sirve para
    las diferentes clases de un modelo de clasificación.
    \item \textbf{modificación del modelo:} se ha cambiado el modelo de xgboost regressor a un modelo de
    clasificación, en concreto se ha utilizado un xgboost classifier. 
    \item \textbf{modificación de la métrica:} se ha cambiado la métrica de error medio absoluto porcentual
    por la de precisión.
\end{itemize}

Este proyecto a tenido una duración aproximada de 2 horas. Una vez finalizado, se ha creado una nueva
plantilla de clasificación a partir de este proyecto para futuros proyectos de clasificación. Esta nueva
plantilla es la que se va a utilizar en el segundo proyecto de clasificación. En este segundo proyecto
el objetivo es transformar la plantilla de clasificación en una que utilice la librería Sktime. Para ello,
se ha realizado una investigación previa sobre la librería y que funcionalidades vienen ya implementadas. 

Dentro de la librería Sktime, se han encontrado una serie de funcionalidades que son de gran utilidad,
como la posibilidad de importar uno de los modelos de clasificación dentro de la propia librería, realizar
una validación cruzada, division de los datos en ventanas temporales, entro otras. Esta adaptación ha
tenido una duración aproximada de 30 minutos ya que la librería proporciona una base sólida para el desarrollo
de proyectos. Una vez finalizado, se ha actualizado la plantilla de clasificación para que funcione con 
Sktime de forma predeterminada.

\subsubsection{Proyectos de detección de anomalías}
Un proyecto de detección de anomalías se enfoca en identificar patrones inusuales o 
atípicos en datos temporales. Estas anomalías pueden indicar problemas, riesgos o 
eventos inesperados en sistemas. La detección de anomalías 
es crucial en campos como la seguridad informática, el mantenimiento predictivo, la 
detección de fraudes, entre otros. Los proyectos de detección de anomalías implican la e
exploración y modelado de datos históricos para comprender los patrones normales e identificar 
desviaciones significativas de esos patrones. Podemos encontrar el siguiente proyectos de detección de anomalías:

\begin{itemize}
    \item \textbf{Proyecto 1:} detección de anomalías en el tráfico de coches en la ciudad de Nueva York.
    En este proyecto se ha utilizado el dataset \textit{New York City Taxi Fare Prediction} \cite{Traffic_NY}.
    Este dataset contiene información sobre el tráfico de coches en la ciudad de Nueva York desde 2015
    hasta 2018.
\end{itemize}

% .
% ├── components
% │   ├── data
% │   │   ├── __init__.py
% │   │   ├── process_data.py
% │   │   └── read_dataset.py
% │   ├── model
% │   │   ├── __init__.py
% │   │   └── isolation_forest.py
% │   └── visualization
% │       ├── __init__.py
% │       └── show_outliers.py
% ├── __init__.py
% ├── settings
% │   ├── __init__.py
% │   ├── metadata.py
% │   └── train_params.py
% ├── train.py
% └── utils
%     ├── __init__.py
%     └── logger.py


\subsubsection{Proyectos de automl}
AutoML, o aprendizaje automático automático, es un enfoque que utiliza algoritmos 
para automatizar el proceso de selección, entrenamiento y ajuste de modelos de 
machine learning. Con la intención de mejorar el rendimiento de los modelos y
explorar que tan útil puede ser esta herramienta en el desarrollo de proyectos
de series temporales, vamos a reutilizar el dataset del proyecto 1 de forecasting
para realizar una plantilla de automl enfocada en el forecasting.\medskip

El AutoML se encarga de probar una variedad de modelos y configuraciones 
para encontrar la combinación óptima que maximice la precisión de nuestras 
predicciones, lo que potencialmente nos permitirá obtener resultados más precisos 
y robustos en comparación con nuestro modelo inicial. La idea es crear una plantilla
que reutilice el contenido previo y con la mínima intervención del usuario, sea capaz
de probar diferentes modelos de forecasting de manera automática.\medskip

La arquitectura de la plantilla en AutoMl se basa en la utilización del patrón
de diseño de estrategia. Este patrón de diseño permite definir una familia de algoritmos,
encapsular cada uno de ellos y hacerlos intercambiables. En este caso, estos algoritmos
recibirán la lista de modelos con sus diferentes hiperparámetros y los resultados de las
iteraciones anteriores. Gracias a esto, las diferentes estrategias podrán realizar la
búsqueda de una manera inteligente. La plantilla base es muy simple y cuenta con dos estrategias 
y siete modelos pero la idea es que en un futuro pueda ser ampliada.\medskip

La lista de modelos que esta plantilla soporta es la siguiente: \textit{LinearRegression, 
DecisionTreeRegressor, RandomForestRegressor, XGBRegressor, LGBMRegressor, CatBoostRegressor
y Neural Network}. Por otro lado, las estrategias que se han implementado son las siguientes:

\begin{itemize}
    \item \textbf{Prueba de la lista de modelos:} para garantizar que la lista
    de modelos y sus correspondientes sets de hiperparámetros sean válidos, se
    realiza una primera pasada de todos los modelos con los hiperparámetros por defecto.
    Esta serie de hiperparámetros por defecto se han seleccionado de manera que sean
    los que mejor se suelen ajustar a la mayoría de los casos. Cada modelo tiene una
    lista diferente de hiperparámetros.
    \item \textbf{Optimización mediante Optuna:} una vez que se ha probado todos los modelos
    con los hiperparámetros por defecto, se seleccionan los tres mejores modelos de esa lista
    de resultados y se realiza una optimización de hiperparámetros mediante Optuna. Optuna
    es una librería de optimización de hiperparámetros que se encarga de encontrar la combinación
    de hiperparámetros que maximiza una métrica dada. En nuestro caso, la métrica que se
    utiliza es el error medio absoluto porcentual.
\end{itemize}

Después de lanzar este proceso sobre el dataset de forecasting, se ha obtenido
un error medio absoluto porcentual del 8.3\% con el modelo XGBRegressor. Esta proceso
ha tenido una duración aproximada de 1 hora y 20 minutos y ha supuesto una mejora de
1.2 puntos porcentuales en comparación con el modelo base. 